{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80126d86-e5a4-4651-8264-497419af3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables setup\n",
    "date = \"2025-2-23\"\n",
    "industry = \"AI\"\n",
    "firm = \"Nvidia\"\n",
    "tic = \"NVDA\"\n",
    "\n",
    "# retrieving historical price of all firms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from yahoo_fin.stock_info import get_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. Stock Info\n",
    "price = yf.Ticker(tic).info['currentPrice']\n",
    "share = yf.Ticker(tic).info['sharesOutstanding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e568e7-fbd8-4c24-8418-48953aa28aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. FRED Risk-free rate\n",
    "api_key         = ''      # FRED API key\n",
    "series_id       = ''                                 # Series ID for the 10-year US Treasury bond yield\n",
    "url             = f'https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&file_type=json'  # Construct the URL for the FRED API request\n",
    "response        = requests.get(url)                       # Send the request to the FRED API and store the response\n",
    "data            = response.json()                         # Convert the response to a JSON object\n",
    "observation     = data['observations'][-1]                # Extract the most recent observation (i.e., the observation with the latest date)\n",
    "\n",
    "risk_free_rate  = float(observation['value']) / 100 \n",
    "discount = risk_free_rate + 0.02 + 1\n",
    "\n",
    "# 2. Financial Statements \n",
    "summary_df = pd.DataFrame(yf.Ticker(tic).financials.T)\n",
    "summary_df.index.name = 'Date'\n",
    "summary_df = summary_df[['Total Revenue', 'Cost Of Revenue','Gross Profit', 'Normalized EBITDA','Operating Expense', \n",
    "                         'Operating Income', 'EBIT', 'Net Income', 'Diluted EPS']]\n",
    "balance_df = pd.DataFrame(yf.Ticker(tic).balance_sheet.T)\n",
    "balance_df.index.name = 'Date'\n",
    "balance_df = balance_df[['Cash Cash Equivalents And Short Term Investments', \"Tangible Book Value\", 'Receivables',  'Total Assets',\n",
    "                          'Total Debt', 'Stockholders Equity', 'Current Assets', 'Current Liabilities','Retained Earnings',\n",
    "                          'Share Issued', 'Total Capitalization', 'Goodwill And Other Intangible Assets']]\n",
    "cashflow_df = pd.DataFrame(yf.Ticker(tic).cashflow.T)\n",
    "cashflow_df.index.name = 'Date'\n",
    "cashflow_df = cashflow_df[['Free Cash Flow', 'End Cash Position', 'Beginning Cash Position', 'Capital Expenditure', 'Depreciation And Amortization',\n",
    "                           'Change In Working Capital','Operating Cash Flow', 'Investing Cash Flow', 'Financing Cash Flow']]\n",
    "\n",
    "financial_df = pd.merge(balance_df, summary_df, on='Date', how='outer')\n",
    "financial_df = pd.merge(financial_df, cashflow_df,  on='Date', how='outer')\n",
    "financial_df[\"Cash\"] = financial_df[\"Cash Cash Equivalents And Short Term Investments\"]\n",
    "financial_df[\"BV\"] = financial_df[\"Tangible Book Value\"]\n",
    "financial_df[\"NWC\"] = financial_df[\"Current Assets\"] - financial_df[\"Current Liabilities\"] + financial_df[\"Cash\"] \n",
    "financial_df[\"NWC_change\"] = financial_df[\"NWC\"] - financial_df[\"NWC\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef51707a-ca1a-44f6-8fad-2c719e7d0b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency YE-JAN will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:213: EstimationWarning: Model has no free parameters to estimate. Set optimized=False to suppress this warning\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Prediction: [26578000000.000004, 32843700000.000004, 39109400000.000015, 45375100000.000015, 51640800000.000015, 57906500000.000015, 64172200000.000015, 70437900000.00002, 76703600000.00003, 82969300000.00003]\n",
      "Arima Prediction: [10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0]\n",
      "Exponential Prediction: [9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0]\n",
      "Lstm Prediction: [22287139432.224846, 14964913131.048056, 2199913542.4993763, 8223477801.318424, 19812201100.31524, 28843751397.419655, 13063037722.311884, 4139323698.8570147, 4720606375.919956, 21637676201.870102]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def predict_fcf(method='linear', periods=10, lookback=3, epochs=100):\n",
    "    fcf_data = financial_df[\"Free Cash Flow\"].dropna().astype('float64')\n",
    "    \n",
    "    if method == 'linear':\n",
    "        X = np.arange(len(fcf_data)).reshape(-1, 1)\n",
    "        model = LinearRegression().fit(X, fcf_data)\n",
    "        return model.predict(np.arange(len(fcf_data), len(fcf_data) + periods).reshape(-1, 1)).tolist()\n",
    "    \n",
    "    elif method == 'arima':\n",
    "        best_model = auto_arima(fcf_data, seasonal=False, stepwise=True, suppress_warnings=True)\n",
    "        model_fit = ARIMA(fcf_data, order=best_model.order).fit()\n",
    "        return model_fit.forecast(steps=periods).tolist()\n",
    "    \n",
    "    elif method == 'exponential':\n",
    "        model = SimpleExpSmoothing(fcf_data).fit(smoothing_level=0.2, optimized=True)\n",
    "        return model.forecast(periods).tolist()\n",
    "    \n",
    "    elif method == 'lstm':\n",
    "        scaler = StandardScaler()\n",
    "        fcf_scaled = scaler.fit_transform(np.array(fcf_data).reshape(-1, 1))\n",
    "        \n",
    "        X, y = [], []\n",
    "        for i in range(len(fcf_scaled) - lookback):\n",
    "            X.append(fcf_scaled[i:i + lookback])\n",
    "            y.append(fcf_scaled[i + lookback])      \n",
    "        X, y = np.array(X).reshape(-1, lookback, 1), np.array(y)\n",
    "        \n",
    "        model = Sequential([\n",
    "            LSTM(100, activation='tanh', return_sequences=True, input_shape=(lookback, 1)),\n",
    "            Dropout(0.2),  \n",
    "            LSTM(100, activation='tanh'),\n",
    "            Dropout(0.2), \n",
    "            Dense(1)\n",
    "        ])     \n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "        model.fit(X, y, epochs=epochs, verbose=0, callbacks=[keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)])\n",
    "        \n",
    "        future_fcf, last_values = [], list(fcf_scaled[-lookback:])\n",
    "        for _ in range(periods):\n",
    "            X_input = np.array(last_values).reshape(1, lookback, 1)\n",
    "            pred_scaled = model.predict(X_input, verbose=0)[0, 0]\n",
    "            pred = scaler.inverse_transform([[pred_scaled]])[0, 0]  \n",
    "            future_fcf.append(pred)\n",
    "            last_values.append([pred_scaled])\n",
    "            last_values.pop(0)\n",
    "        \n",
    "        return future_fcf\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose from 'linear', 'arima', 'exponential', 'lstm'\")\n",
    "\n",
    "methods = ['linear', 'arima', 'exponential', 'lstm']\n",
    "predictions = {method: predict_fcf(method) for method in methods}\n",
    "for method, result in predictions.items():\n",
    "    print(f'{method.capitalize()} Prediction: {result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4a3bcc-a667-4ea2-b12c-2ffc46acd630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Prediction: [26578000000.000004, 32843700000.000004, 39109400000.000015, 45375100000.000015, 51640800000.000015, 57906500000.000015, 64172200000.000015, 70437900000.00002, 76703600000.00003, 82969300000.00003]\n",
      "Arima Prediction: [10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0, 10913750000.0]\n",
      "Exponential Prediction: [9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0, 9457704000.0]\n",
      "Lstm Prediction: [22287139432.224846, 14964913131.048056, 2199913542.4993763, 8223477801.318424, 19812201100.31524, 28843751397.419655, 13063037722.311884, 4139323698.8570147, 4720606375.919956, 21637676201.870102]\n",
      "Terminal Value of Gordon Growth Model: $927721000000.0\n",
      "Terminal Value of Exit Multiple Model: $338038500000.0\n"
     ]
    }
   ],
   "source": [
    "def terminal_value(method='growth', TV_growth=0.04, discount_rate=0.1, exit_multiple=None):\n",
    "    if method == 'growth':\n",
    "        fcf_data = financial_df[\"Free Cash Flow\"].dropna().astype('float64').values\n",
    "        return round((fcf_data[-1] * (1 + TV_growth)) / (discount_rate - TV_growth), 1)\n",
    "    elif method == 'ebitda':\n",
    "        EBITDA_data = financial_df[\"Normalized EBITDA\"].dropna().astype('float64').values\n",
    "        return round(EBITDA_data[-1] * exit_multiple, 1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose from 'growth' or 'ebitda'\")\n",
    "\n",
    "growth_TV = terminal_value(method='growth', TV_growth=0.03, discount_rate=0.06)\n",
    "ebitda_TV = terminal_value(method='ebitda', exit_multiple=9.5)\n",
    "\n",
    "for method, result in predictions.items():\n",
    "    print(f'{method.capitalize()} Prediction: {result}')\n",
    "\n",
    "print(f\"Terminal Value of Gordon Growth Model: ${growth_TV}\")\n",
    "print(f\"Terminal Value of Exit Multiple Model: ${ebitda_TV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e27670d-7bf5-41b0-9fd4-ed8a83f4ec5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Linear DCF': 17.846837697441174} current price 137.72\n"
     ]
    }
   ],
   "source": [
    "linear_fcf = predict_fcf(method='linear')\n",
    "# Intrinsic value\n",
    "def dcf_EV(fcf_data= linear_fcf, discount=0.1, TV = ebitda_TV,  share = share, periods = 10):\n",
    "    fcf_data = np.array(fcf_data)\n",
    "    periods = len(fcf_data)\n",
    "    discount_factors = (1 + discount) ** np.arange(1, periods + 1)\n",
    "    pv_fcf = np.sum(fcf_data / discount_factors)\n",
    "    pv_TV = TV / ((1 + discount) ** periods)\n",
    "    intrinsic_price = round(pv_fcf + pv_TV, 2)/share\n",
    "    return intrinsic_price\n",
    "\n",
    "intrinsic_values = {\n",
    "    \"Linear DCF\": dcf_EV() }\n",
    "\n",
    "print(intrinsic_values, \"current price\", price)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a927a20-4a14-483b-96a2-77d9a3398143",
   "metadata": {},
   "source": [
    "## (III). Analysis Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e14f446-0118-40cd-ac57-db8c8c1931a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report successfully saved to Financial_Analysis_Report.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "from docx.shared import Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "\n",
    "firm = \"Nvidia\"\n",
    "class FinancialAnalyst:\n",
    "    from openai import OpenAI\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "    \n",
    "    def ask(self, prompt):\n",
    "        client = self.OpenAI(api_key=self.api_key)\n",
    "        response = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "          max_tokens=4000,  n=1,  stop=None,  temperature=0.95,top_p= 0.95,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    def generate_response(self, prompt: str) -> str:\n",
    "        response = self.ask(prompt)\n",
    "        return response\n",
    "    # \n",
    "    def analyze_part1(self, company_name: str) -> dict:\n",
    "        part1_prompts = {\n",
    "            \"Business Model\": f\"tell me about the business model of {firm}\",\n",
    "            \"Geographical Segmentation\": f\"tell me the geographical segmentation of business of {firm}\",\n",
    "            \"Product Segment\": f\"What is the product segment of {firm}\" ,           \n",
    "            \"Industry Overview\": f\"tell me the industry overview of {firm}\",\n",
    "            \"SWOT\": f\"briefly describe the strengths, weaknesses, opportunities and threats on the business model of {firm}\",\n",
    "            \"Growth Opportunity\": f\"What is the growth opportunity for industry of {firm}\",            \n",
    "            \"Competitive Analysis\": f\"give me a competitive analysis of {firm}\",\n",
    "            \"Simulation\": f\"Using 2020 data, can you give me value of brownian motion monte carlo simulation for {firm}\",\n",
    "            \"Valuation\": f\"perform relative valuation of {firm} using previous competitors calculate industry risk for microsoft using previous data\"\n",
    "       }\n",
    "\n",
    "        part1_results = {}\n",
    "        for key, prompt in part1_prompts.items():\n",
    "            part1_results[key] = self.generate_response(prompt)\n",
    "        return part1_results\n",
    "\n",
    "    def save_report_to_word(self, company_name: str):\n",
    "            document = Document()\n",
    "            document.add_heading('Comprehensive Financial Analysis Report', level=1)\n",
    "            style = document.styles['Normal']\n",
    "            font = style.font\n",
    "            font.name = 'Times New Roman'\n",
    "            font.size = Pt(12)\n",
    "            \n",
    "            document.add_heading('Industrial Analysis', level=2)\n",
    "            response = self.analyze_part1(company_name)\n",
    "            for i,j in response.items():\n",
    "                document.add_heading(i,level=3)\n",
    "                paragraph = document.add_paragraph(j)\n",
    "                \n",
    "            document.save('Financial_Analysis_Report.docx')\n",
    "            print(\"Report successfully saved to Financial_Analysis_Report.docx\")\n",
    "    \n",
    "gpt = FinancialAnalyst(api_key=\"\")\n",
    "gpt.save_report_to_word(\"{firm} financial analysis_{date}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
